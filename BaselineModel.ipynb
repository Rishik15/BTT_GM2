{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b99a7f",
   "metadata": {},
   "source": [
    "## Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f143b48",
   "metadata": {},
   "source": [
    "### Context\n",
    "  Investors need a lightweight, data-driven tool to assess \"grit\" in\n",
    "  business leaders\n",
    "  and CEO funding applicants. Grit (perseverance and passion for\n",
    "  long-term goals) is\n",
    "  a strong predictor of long-term business success.\n",
    "\n",
    "### Modeling Objectives\n",
    "\n",
    "  **Regression Task:** Predict continuous grit score (1-5 scale)\n",
    "  - Success criteria: R² > 0.3, RMSE < 0.6\n",
    "  - Justification: R² > 0.3 means explaining 30%+ of variance in grit,\n",
    "  meaningful\n",
    "    for psychological constructs. RMSE < 0.6 = ~12% error on 1-5 scale.\n",
    "\n",
    "  **Classification Task:** Predict high/low grit (binary)\n",
    "  - Success criteria: Accuracy > 70%, F1 > 0.70\n",
    "  - Justification: 70%+ accuracy significantly beats random guessing\n",
    "  (50%).\n",
    "    F1 score ensures balanced precision/recall for investor decisions.\n",
    "\n",
    "  **Business Objective:** Minimize survey length while maintaining R² >\n",
    "  0.40\n",
    "  - Target: Reduce from 62 questions (Big Five + Grit items) to ≤15\n",
    "  questions\n",
    "  - Constraint: Must maintain R² > 0.40 (higher bar for practical\n",
    "  deployment)\n",
    "  - Trade-off: Balance prediction accuracy vs. respondent\n",
    "  burden/completion rate\n",
    "\n",
    "  ### Current Baseline Performance \n",
    "  - Linear Regression: R² = 0.489, RMSE = 0.498 ✓ (exceeds targets)\n",
    "  - Logistic Regression: Accuracy = 76.3%, F1 = 76.7% ✓ (exceeds\n",
    "  targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a087acb",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "931ba819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9104b",
   "metadata": {},
   "source": [
    "### Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c35a88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>surveyelapse</th>\n",
       "      <th>GS1</th>\n",
       "      <th>GS2</th>\n",
       "      <th>GS3</th>\n",
       "      <th>GS4</th>\n",
       "      <th>GS5</th>\n",
       "      <th>GS6</th>\n",
       "      <th>GS7</th>\n",
       "      <th>...</th>\n",
       "      <th>browser</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Grit</th>\n",
       "      <th>highgrit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>JP</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>3</td>\n",
       "      <td>337</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>US</td>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>36</td>\n",
       "      <td>212</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>EU</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Microsoft Internet Explorer</td>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>AE</td>\n",
       "      <td>592</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>726</td>\n",
       "      <td>311</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>AU</td>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>376</td>\n",
       "      <td>407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index country  surveyelapse  GS1  GS2  GS3  GS4  GS5  GS6  GS7  ...  \\\n",
       "0      4      JP           340    5    2    3    3    2    4    2  ...   \n",
       "1      6      US           126    4    1    3    2    1    5    1  ...   \n",
       "2      8      EU           130    5    3    3    5    4    5    5  ...   \n",
       "3     10      AE           592    5    3    3    2    4    3    3  ...   \n",
       "4     11      AU           217    3    1    1    2    1    3    1  ...   \n",
       "\n",
       "                       browser  introelapse  testelapse  Extraversion  \\\n",
       "0                      Firefox            3         337           1.2   \n",
       "1                       Chrome           36         212           4.0   \n",
       "2  Microsoft Internet Explorer           14         183           4.4   \n",
       "3                       Chrome          726         311           3.0   \n",
       "4                      Firefox          376         407           2.0   \n",
       "\n",
       "   Neuroticism  Agreeableness  Conscientiousness  Openness      Grit  highgrit  \n",
       "0          2.5            3.3                3.8       3.0  3.083333         0  \n",
       "1          2.0            3.6                3.4       5.0  2.583333         0  \n",
       "2          4.5            4.7                4.0       4.3  4.250000         1  \n",
       "3          4.6            3.6                3.8       3.4  3.166667         0  \n",
       "4          1.1            3.4                3.9       4.4  2.000000         0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned_grit_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2c955ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Columns: 101 entries, index to highgrit\n",
      "dtypes: float64(6), int64(82), object(13)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1074ceb",
   "metadata": {},
   "source": [
    "### Splitting the data into Train and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cab17769",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']]\n",
    "y = df['Grit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7154ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Openness  Conscientiousness  Extraversion  Agreeableness  Neuroticism\n",
       "0       3.0                3.8           1.2            3.3          2.5\n",
       "1       5.0                3.4           4.0            3.6          2.0\n",
       "2       4.3                4.0           4.4            4.7          4.5\n",
       "3       3.4                3.8           3.0            3.6          4.6\n",
       "4       4.4                3.9           2.0            3.4          1.1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a84efbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.083333\n",
       "1    2.583333\n",
       "2    4.250000\n",
       "3    3.166667\n",
       "4    2.000000\n",
       "Name: Grit, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "099d74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (2200, 5)\n",
      "y shaep:  (2200,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shaep: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c60871a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e20a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1760, 5)\n",
      "y_train shape:  (1760,)\n",
      "X_test shape:  (440, 5)\n",
      "y_test shape:  (440,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9922d1",
   "metadata": {},
   "source": [
    "We are going to test the data on baseline models. The models we will be using are:\n",
    "\n",
    "1. Mean model\n",
    "2. Median model\n",
    "3. Simple Linear Regresssion\n",
    "\n",
    "The metrics we will be using are R2, MAE, MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa690a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, pred, name):\n",
    "    print(f\"{name} Model Results\")\n",
    "    print(f\"R²  : {r2_score(true, pred):.4f}\")\n",
    "    print(f\"MAE : {mean_absolute_error(true, pred):.4f}\")\n",
    "    print(f\"MSE : {mean_squared_error(true, pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4c81b",
   "metadata": {},
   "source": [
    "### Mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2975b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Baseline Model Results\n",
      "R²  : -0.0003\n",
      "MAE : 0.5718\n",
      "MSE : 0.4743\n"
     ]
    }
   ],
   "source": [
    "mean_pred = np.full(shape=y_test.shape, fill_value=y_train.mean())\n",
    "\n",
    "evaluate_model(y_test, mean_pred, \"Mean Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74992c9a",
   "metadata": {},
   "source": [
    "### Median model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d824eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Baseline Model Results\n",
      "R²  : -0.0060\n",
      "MAE : 0.5718\n",
      "MSE : 0.4770\n"
     ]
    }
   ],
   "source": [
    "median_pred = np.full(shape=y_test.shape, fill_value=y_train.median())\n",
    "\n",
    "evaluate_model(y_test, median_pred, \"Median Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90a69e",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8ad6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "698a5756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Results\n",
      "R²  : 0.4855\n",
      "MAE : 0.3951\n",
      "MSE : 0.2440\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, lr_pred, \"Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50187a1f",
   "metadata": {},
   "source": [
    "The baseline modeling results provide an initial understanding of how well grit can be predicted using simple statistical approaches. Both the mean and median models performed poorly, with negative R2 values and identical error scores, indicating that these models are unable to capture any meaningful variation in grit scores across individuals. In contrast, the linear regression model, which used the Big Five personality traits as predictors, showed a substantial improvement, achieving an R2 of approximately 0.49 and significantly lower MAE and MSE values. This suggests that nearly half of the variability in grit can be explained by personality traits alone, with traits such as conscientiousness likely playing a strong role, which is observed from our EDA. Overall, these results confirm that while trivial models offer no predictive value, linear regression provides a meaningful baseline and justifies moving forward with more advanced modeling techniques to further improve prediction and understand underlying relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418c2fa",
   "metadata": {},
   "source": [
    "### Using only 'Conscientiousness' in the linear model to see its impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7aa2ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[ 'Conscientiousness']]\n",
    "y = df['Grit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06cc322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e811890",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "81b41da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Results\n",
      "R²  : 0.4278\n",
      "MAE : 0.4243\n",
      "MSE : 0.2713\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, lr_pred, \"Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18e55c",
   "metadata": {},
   "source": [
    "We can see that the other traits do contribute to the model's performance. We will be considering them all the personality traits in out main model or analyze them more later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e577c6",
   "metadata": {},
   "source": [
    "We will use five fold cross validation to evaluate the performance of a basline linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7626c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE per fold: [0.39505942 0.39641015 0.39037359 0.41273381 0.39917258]\n",
      "RMSE per fold: [0.49393897 0.50016897 0.48355819 0.51599462 0.49829142]\n",
      "R^2 per fold: [0.48547012 0.49832952 0.49514649 0.46627077 0.49973973]\n",
      "\n",
      "Average scores:\n",
      "MAE: 0.39874991183193725\n",
      "RMSE: 0.49839043182801124\n",
      "R^2: 0.4889913245440196\n"
     ]
    }
   ],
   "source": [
    "X = df[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']]\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "results = cross_validate(model, X, y, cv = folds, scoring=['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2'])\n",
    "\n",
    "mae = -results['test_neg_mean_absolute_error']\n",
    "rmse = -results['test_neg_root_mean_squared_error']\n",
    "r2 = results['test_r2']\n",
    "\n",
    "print(\"MAE per fold:\", mae)\n",
    "print(\"RMSE per fold:\", rmse)\n",
    "print(\"R^2 per fold:\", r2)\n",
    "\n",
    "print(\"\\nAverage scores:\")\n",
    "print(f\"MAE: {np.mean(mae)}\")\n",
    "print(f\"RMSE: {np.mean(rmse)}\")\n",
    "print(f\"R^2: {np.mean(r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f332d32",
   "metadata": {},
   "source": [
    "The MAE suggests that the predictions deviate from there actual value by about 0.399 which is relatively small. Thr RMSE, which penlizes larger errors more heavily than MAE is 0.498, suggesting that there some larger errors occured. The R^2 suggegests that about 49% of the variability in grit is explained by this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4bc6c",
   "metadata": {},
   "source": [
    "We will use five fold cross validation to evaluate the performance of a basline logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1377338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per fold: [0.75454545 0.74772727 0.75909091 0.78409091 0.76818182]\n",
      "Precision per fold: [0.76146789 0.76056338 0.74369748 0.77489177 0.76651982]\n",
      "Recall per fold: [0.74774775 0.72972973 0.7972973  0.80630631 0.78026906]\n",
      "F1-score per fold: [0.75454545 0.74482759 0.76956522 0.79028698 0.77333333]\n",
      "\n",
      "Average scores:\n",
      "Accuracy: 0.7627272727272727\n",
      "Precision: 0.761428069572373\n",
      "Recall: 0.7722700278754091\n",
      "F1: 0.7665117134388856\n"
     ]
    }
   ],
   "source": [
    "y_log = df[\"highgrit\"]\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "stratified_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = cross_validate(model, X, y_log, cv=stratified_folds, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "acc = results['test_accuracy']\n",
    "prec = results['test_precision']\n",
    "rec = results['test_recall']\n",
    "f1 = results['test_f1']\n",
    "\n",
    "print(\"Accuracy per fold:\", acc)\n",
    "print(\"Precision per fold:\", prec)\n",
    "print(\"Recall per fold:\", rec)\n",
    "print(\"F1-score per fold:\", f1)\n",
    "\n",
    "print(\"\\nAverage scores:\")\n",
    "print(f\"Accuracy: {np.mean(acc)}\")\n",
    "print(f\"Precision: {np.mean(prec)}\")\n",
    "print(f\"Recall: {np.mean(rec)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a31c8d",
   "metadata": {},
   "source": [
    "The results suggest that around 76% of predictions are correct. Precision and recall are balanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
